{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fead27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOSTNAME: 3fa58c0c40d9\n",
      "PWD: /home/jovyan\n",
      "DATA exists?: True\n"
     ]
    }
   ],
   "source": [
    "import os, socket\n",
    "print(\"HOSTNAME:\", socket.gethostname())\n",
    "print(\"PWD:\", os.getcwd())\n",
    "print(\"DATA exists?:\", os.path.exists(\"/home/jovyan/data/yellow_tripdata_2019-01.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5898153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists /home/jovyan/data ? True\n",
      "exists /opt/spark/work-dir/data ? True\n",
      "spark.version = 3.5.0\n",
      "rows = 7696617\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"exists /home/jovyan/data ?\",\n",
    "      os.path.exists(\"/home/jovyan/data/yellow_tripdata_2019-01.parquet\"))\n",
    "print(\"exists /opt/spark/work-dir/data ?\",\n",
    "      os.path.exists(\"/opt/spark/work-dir/data/yellow_tripdata_2019-01.parquet\"))\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"NYC-TLC-Check\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .getOrCreate())\n",
    "\n",
    "print(\"spark.version =\", spark.version)\n",
    "\n",
    "df = spark.read.parquet(\"/opt/spark/work-dir/data/yellow_tripdata_2019-01.parquet\")\n",
    "print(\"rows =\", df.count())\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367cae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45c2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+------------+-----------+----------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|payment_type|fare_amount|tip_amount|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+------------+-----------+----------+------------+\n",
      "|1       |2019-01-01 00:46:40 |2019-01-01 00:53:20  |1.0            |1.5          |151         |239         |1           |7.0        |1.65      |9.95        |\n",
      "|1       |2019-01-01 00:59:47 |2019-01-01 01:18:59  |1.0            |2.6          |239         |246         |1           |14.0       |1.0       |16.3        |\n",
      "|2       |2018-12-21 13:48:30 |2018-12-21 13:52:40  |3.0            |0.0          |236         |236         |1           |4.5        |0.0       |5.8         |\n",
      "|2       |2018-11-28 15:52:25 |2018-11-28 15:55:45  |5.0            |0.0          |193         |193         |2           |3.5        |0.0       |7.55        |\n",
      "|2       |2018-11-28 15:56:57 |2018-11-28 15:58:33  |5.0            |0.0          |193         |193         |2           |52.0       |0.0       |55.55       |\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+------------+-----------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "|min_pickup         |max_pickup         |min_dropoff        |max_dropoff        |\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "|2001-02-02 14:55:07|2088-01-24 00:25:39|2001-02-02 15:07:27|2088-01-24 07:28:25|\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "+-------------+-------+\n",
      "|bucket       |count  |\n",
      "+-------------+-------+\n",
      "|in_jan_2019  |7696080|\n",
      "|out_of_window|537    |\n",
      "+-------------+-------+\n",
      "\n",
      "=== Plano (não executa) ===\n",
      "== Physical Plan ==\n",
      "*(1) Filter ((isnotnull(tpep_pickup_datetime#1133) AND (tpep_pickup_datetime#1133 >= 2019-01-01 00:00:00)) AND (tpep_pickup_datetime#1133 < 2019-02-01 00:00:00))\n",
      "+- *(1) ColumnarToRow\n",
      "   +- FileScan parquet [VendorID#1132L,tpep_pickup_datetime#1133,tpep_dropoff_datetime#1134,passenger_count#1135,trip_distance#1136,RatecodeID#1137,store_and_fwd_flag#1138,PULocationID#1139L,DOLocationID#1140L,payment_type#1141L,fare_amount#1142,extra#1143,mta_tax#1144,tip_amount#1145,tolls_amount#1146,improvement_surcharge#1147,total_amount#1148,congestion_surcharge#1149,airport_fee#1150] Batched: true, DataFilters: [isnotnull(tpep_pickup_datetime#1133), (tpep_pickup_datetime#1133 >= 2019-01-01 00:00:00), (tpep_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/opt/spark/work-dir/data/yellow_tripdata_2019-01.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(tpep_pickup_datetime), GreaterThanOrEqual(tpep_pickup_datetime,2019-01-01T00:00), Less..., ReadSchema: struct<VendorID:bigint,tpep_pickup_datetime:timestamp_ntz,tpep_dropoff_datetime:timestamp_ntz,pas...\n",
      "\n",
      "\n",
      "\n",
      "=== Agora executa (count) ===\n",
      "rows jan: 7696080\n",
      "+----------------------+-------+\n",
      "|bucket                |count  |\n",
      "+----------------------+-------+\n",
      "|before_2019-01-01     |441    |\n",
      "|in_jan_2019           |7696080|\n",
      "|on_or_after_2019-02-01|96     |\n",
      "+----------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"NYC-TLC-01\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .getOrCreate())\n",
    "\n",
    "# local do arquivo\n",
    "df = spark.read.parquet(\"/opt/spark/work-dir/data/yellow_tripdata_2019-01.parquet\")\n",
    "\n",
    "# abertura do arquivo\n",
    "df.select(\n",
    "    \"VendorID\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"payment_type\",\n",
    "    \"fare_amount\",\n",
    "    \"tip_amount\",\n",
    "    \"total_amount\"\n",
    ").show(5, truncate=False)\n",
    "\n",
    "# análise das datas contidas no arquivo\n",
    "df.select(\n",
    "    F.min(\"tpep_pickup_datetime\").alias(\"min_pickup\"),\n",
    "    F.max(\"tpep_pickup_datetime\").alias(\"max_pickup\"),\n",
    "    F.min(\"tpep_dropoff_datetime\").alias(\"min_dropoff\"),\n",
    "    F.max(\"tpep_dropoff_datetime\").alias(\"max_dropoff\"),\n",
    ").show(truncate=False)\n",
    "\n",
    "# definição do período de análise\n",
    "in_jan = (\n",
    "    (F.col(\"tpep_pickup_datetime\") >= F.lit(\"2019-01-01\")) &\n",
    "    (F.col(\"tpep_pickup_datetime\") <  F.lit(\"2019-02-01\"))\n",
    ")\n",
    "\n",
    "# contar quantos registros dentro da janela de interesse x registros fora da janela\n",
    "counts = (df\n",
    "    .select(F.when(in_jan, F.lit(\"in_jan_2019\")).otherwise(F.lit(\"out_of_window\")).alias(\"bucket\"))\n",
    "    .groupBy(\"bucket\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "counts.show(truncate=False)\n",
    "\n",
    "pickup = F.col(\"tpep_pickup_datetime\")\n",
    "\n",
    "cond = (pickup >= F.lit(\"2019-01-01\")) & (pickup < F.lit(\"2019-02-01\"))\n",
    "\n",
    "df_jan = df.filter(cond)\n",
    "\n",
    "print(\"=== Plano (não executa) ===\")\n",
    "df_jan.explain()\n",
    "\n",
    "print(\"\\n=== Agora executa (count) ===\")\n",
    "print(\"rows jan:\", df_jan.count())\n",
    "\n",
    "bucket2 = (\n",
    "    F.when(pickup < F.lit(\"2019-01-01\"), F.lit(\"before_2019-01-01\"))\n",
    "     .when(pickup >= F.lit(\"2019-02-01\"), F.lit(\"on_or_after_2019-02-01\"))\n",
    "     .otherwise(F.lit(\"in_jan_2019\"))\n",
    ")\n",
    "\n",
    "(df\n",
    " .select(bucket2.alias(\"bucket\"))\n",
    " .groupBy(\"bucket\")\n",
    " .count()\n",
    " .orderBy(\"bucket\")\n",
    ").show(truncate=False)\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
